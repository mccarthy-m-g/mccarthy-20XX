# Methods

## Data

In this study, we used EEG data previously collected by our lab as part of a larger study. The larger study involved the collection of EEG recordings during resting state (eyes open and eyes closed) and during a lexical decision task [@meyerschvaneveldt_FacilitationRecognizingPairs_1971] across three repeated measures sessions. The data collected during the lexical decision task is described in detail by @cnuddeetal_IncreasedNeuralEfficiency_2021 and is available at <https://osf.io/da478/>. Here we only use the EEG recordings collected during resting state, which has not been previously described or made publicly available. All participants provided written informed consent before taking part in the study and were provided with monetary compensation for their participation. Ethics approval was received from the Conjoint Faculties Research Ethics Board of the University of Calgary.

### Participants

```{r demographic-descriptives}
tar_load(participant_descriptives)
tar_load(participant_descriptives_final)
```

`r stringr::str_to_sentence(xfun::numbers_to_words(participant_descriptives$n))` healthy adults (`r participant_descriptives$male` males, `r participant_descriptives$female` females) whose ages ranged from `r participant_descriptives$years_age_min` to `r participant_descriptives$years_age_max` years (M = `r papaja::apa_num(participant_descriptives$years_age_mean)`, SD = `r papaja::apa_num(participant_descriptives$years_age_sd)`) and whose years of education ranged from `r participant_descriptives$years_education_min` to `r participant_descriptives$years_education_max` years (M = `r papaja::apa_num(participant_descriptives$years_education_mean)`, SD = `r papaja::apa_num(participant_descriptives$years_education_sd)`) participated in the study. All participants were right handed, spoke English as a first language, and had normal or corrected-to-normal vision. Exclusion criteria included a history of neurological disease or disorder, mental illness, head trauma, alcoholism or drug abuse, or use of psychotropic medications in the last two years preceding data collection. We excluded EEG data for analysis from four participants because they did not participate in the final session, and three participants because they had one or more recordings with excessive noise. The final sample used for analysis consisted of `r xfun::numbers_to_words(participant_descriptives_final$n)` participants (`r participant_descriptives_final$male` males, `r participant_descriptives_final$female` females) whose ages ranged from `r participant_descriptives_final$years_age_min` to `r participant_descriptives_final$years_age_max` years (M = `r papaja::apa_num(participant_descriptives_final$years_age_mean)`, SD = `r papaja::apa_num(participant_descriptives_final$years_age_sd)`) and whose years of education ranged from `r participant_descriptives_final$years_education_min` to `r participant_descriptives_final$years_education_max` years (M = `r papaja::apa_num(participant_descriptives_final$years_education_mean)`, SD = `r papaja::apa_num(participant_descriptives_final$years_education_sd)`).

### Electrophysiological Data Acquisition

Electrophysiological data acquisition was completed in a dimly lit, radio frequency shielded, and sound attenuated chamber. During each session, an EasyCap with 64 gel-based active electrodes positioned following the 10-10 system [@chatrianetal_TenPercentElectrode_1985; @chatrianetal_ModifiedNomenclature10_1988] was used to continuously record electrophysiological activity at the scalp (Brain Products GmbH, Gilching, Germany). Channel Cz was used as the reference electrode. A Brain Vision Solutions actiCHamp amplifier was used to amplify microvolt signals from the electrodes and transform them into digital format for storage and analysis (Brain Products GmbH, Gilching, Germany). All data were sampled at 500 Hz, and band limited with a built-in 0.05-100 Hz band-pass filter. All electrode impedances were below 17 kW at the start of recording. EEG recording lasted for a total of 80 minutes. We first recorded five minutes of eyes open and five minutes of eyes closed resting state date, with the order of these conditions counter-balanced across participants. This was followed by approximately 60 minutes of task state data recorded during performance of a lexical decision task [for a detailed description, see @cnuddeetal_IncreasedNeuralEfficiency_2021]. Finally, eyes open and eyes closed resting state data were recorded for five minutes each, again counter-balanced across participants.

Across all three sessions, we collected a total of 30 minutes eyes open resting state data (over 6 recordings) and 30 minutes eyes closed resting state data (over 6 recordings) from each participant. The time between the first and second session ranged from `r participant_descriptives_final$days_pre_to_post_min` to `r participant_descriptives_final$days_pre_to_post_max` days (M = `r papaja::apa_num(participant_descriptives_final$days_pre_to_post_mean)`, SD = `r papaja::apa_num(participant_descriptives_final$days_pre_to_post_sd)`), and between the second and third session ranged from `r participant_descriptives_final$days_post_to_followup_min` to `r participant_descriptives_final$days_post_to_followup_max` days (M = `r papaja::apa_num(participant_descriptives_final$days_post_to_followup_mean)`, SD = `r papaja::apa_num(participant_descriptives_final$days_post_to_followup_sd)`).

## Software and computational reproducibility

```{r}
r_version <- paste0(R.version$major, ".", R.version$minor)
```

<!--This project comes with a reproducible environment, using Docker <https://www.docker.com>, that includes everything needed to run its code or view its outputs.[^99] Instructions can be found in the study's GitHub or OSF repository.-->All computational steps were done using the open source programming language R [version `r r_version`, <https://www.R-project.org/>\; @R-base]. We maintained a reproducible workflow for the entire pipeline---from data cleaning to reporting---using the targets package [@R-targets], and managed R and Python dependencies using the renv package [@R-renv]. All EEG preprocessing and functional connectivity analysis was done using the open source Python package MNE-Python [version 2.2.0, <https://doi.org/10.5281/zenodo.4338426>\; @gramfortetal_MEGEEGData_2013], which was called from R using the reticulate package [@R-reticulate]. We estimated the RV coefficient using the FactoMineR package [@R-FactoMineR], and fit the mixed beta regression and contrasts using the glmmTMB [@R-glmmTMB] and emmeans [@R-emmeans] packages, respectively. The DHARMa [@R-DHARMa] and performance [@R-performance] packages were used for model diagnostics. All data visualization was done with a combination of the ggplot2 [@R-ggplot2], ggdist [@R-ggdist], ggh4x [@R-ggh4x], ggnewscale [@R-ggnewscale], and patchwork [@R-patchwork] packages. Other computations were done using the tidyverse [@R-tidyverse] suite of packages. Finally, this manuscript itself was written in R Markdown [@R-rmarkdown] using the papaja package's APA template [@R-papaja], and all reported numbers and figures were printed using inline code to ensure their accuracy. A complete record of the R environment and packages used in this study can be found in Tables \@ref(tab:session-info-environment) and \@ref(tab:session-info-packages) in the appendix.

## EEG preprocessing

```{r bads-descriptives}
# Bad channels descriptive statistics
tar_load(bad_channels_descriptives_final)

bad_channels_percent_nrow <- nrow(bad_channels_descriptives_final$count_per_recording)
bad_channels_percent_bad <- bad_channels_descriptives_final$count_per_recording |>
  dplyr::slice(bad_channels_percent_nrow - 1) |>
  dplyr::pull(percent_cumulative)
  
bad_channels_n_min  <- bad_channels_descriptives_final$descriptives$bad_channels_n_min
bad_channels_n_max  <- bad_channels_descriptives_final$descriptives$bad_channels_n_max
bad_channels_n_mode <- bad_channels_descriptives_final$descriptives$bad_channels_n_mode

# Bad segments descriptive statistics
tar_load(bad_segments_descriptives_final)

bad_segments_percent_nrow <- nrow(bad_segments_descriptives_final$count_per_recording)
bad_segments_percent_bad <- bad_segments_descriptives_final$count_per_recording |>
  dplyr::slice(bad_segments_percent_nrow - 1) |>
  dplyr::pull(percent_cumulative)
  
bad_segments_n_min  <- bad_segments_descriptives_final$descriptives$bad_segments_n_min
bad_segments_n_max  <- bad_segments_descriptives_final$descriptives$bad_segments_n_max
bad_segments_n_mode <- bad_segments_descriptives_final$descriptives$bad_segments_n_mode

bad_segments_duration_totals <- bad_segments_descriptives_final$bad_segment_duration_totals |>
  dplyr::pull(sum)
bad_segments_duration_totals_min  <- min(bad_segments_duration_totals)
bad_segments_duration_totals_max  <- max(bad_segments_duration_totals)
bad_segments_duration_totals_mean <- mean(bad_segments_duration_totals)
bad_segments_duration_totals_sd   <- sd(bad_segments_duration_totals)
```

Raw EEG data was preprocessed to remove noise and non-neural artifacts from the data using the following steps. First, following recommendations by @widmannetal_DigitalFilterDesign_2015, a two-pass forward and reverse, zero-phase, non-causal band-pass finite impulse response filter was used to remove slow drift potentials at infraslow frequencies less than 0.10 Hz, line noise at 60.00 Hz, and irrelevant noise fluctuations greater than 60.00 Hz [@decheveignenelken_FiltersWhenWhy_2019; @widmannetal_DigitalFilterDesign_2015]. The finite impulse response filter used a Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation. The lower passband edge and transition bandwidth were set at 0.10 Hz (-12 dB cutoff frequency: 0.05 Hz), and the upper passband edge and transition bandwidth were set at 50.00 Hz (-12 dB cutoff frequency: 56.25 Hz). The filter length was 16501 samples (33.002 seconds). These filter parameters were selected after exploring the difference between raw and filtered signals and verifying that the selected filter parameters improved signal quality over alternative filter parameters or the raw signal [@widmannetal_DigitalFilterDesign_2015]. Second, the data was downsampled from 500 to 200 Hz in order to reduce the size of the data and speed up computations operating on the data. Third, data was rereferenced to the common average reference in order to reduce spatial biases in the signal amplitude of channels caused by their distance to the original reference electrode [@nunezsrinivasan_ElectricFieldsBrain_2006]. Fourth, bad channels and segments were manually marked and removed to prepare the data for ICA decomposition. Channels were marked as bad if they contained excessive noise or drift for a significant portion of the recording. Bad channels were marked in `r papaja::apa_num(bad_channels_percent_bad)`% of recordings, ranging from `r bad_channels_n_min` to `r bad_channels_n_max` bad channels marked per recording with a mode of `r bad_channels_n_mode`. Segments were marked as bad if they contained excessive noise or drift that (1) could interfere with fitting the ICA decomposition due to the amount of variance their component would capture, or (2) was unlikely to be repaired by ICA decomposition.  Bad segments were marked in `r papaja::apa_num(bad_segments_percent_bad)`% of the recordings, ranging from `r bad_segments_n_min` to `r bad_segments_n_max` bad segments marked per recording with a mode of `r bad_segments_n_mode`. The total duration of bad segments per recording across the entire sample ranged from `r papaja::apa_num(bad_segments_duration_totals_min)` to `r papaja::apa_num(bad_segments_duration_totals_max)` seconds long (M = `r papaja::apa_num(bad_segments_duration_totals_mean)`, SD = `r papaja::apa_num(bad_segments_duration_totals_sd)`). Fifth, ICA decomposition fitted using the Picard algorithm [@ablinetal_FasterICAOrthogonal_2017; @ablinetal_FasterIndependentComponent_2018] was performed to remove components carrying muscle artifacts or ocular artifacts (eye blinks, saccades, or horizontal eye movements) from the data. Components carrying artifacts were manually selected and then removed. Finally, bad channels were interpolated using spherical splines [@perrinetal_SphericalSplinesScalp_1989] and put back into the data.

After artifact rejection, the continuous data was divided into epochs and filtered to prepare for functional connectivity analysis. This was a three step process. First, the epochs with an 8 second duration were created at 5 second intervals such that an epoch occurred from 0-8 seconds, 5-13 seconds, 10-18 seconds, and so forth, until the end of the recording. Epochs that contained a bad segment were removed. Second, the epoched data was filtered into five frequency bands---delta ($\delta$, 1-4 Hz), theta ($\theta$, 4-8 Hz), alpha ($\alpha$, 8-13 Hz), beta ($\beta$, 13-30 Hz), and gamma ($\gamma$, 30-50 Hz)---using a two-pass forward and reverse, zero-phase, non-causal band-pass finite impulse response filter. Third, epochs were cropped to a 5 second duration starting 1 second into each epoch such that an epoch then occurred from 1-6 seconds, 6-11 seconds, 11-16 seconds, and so forth.

Filtering the data into five frequency bands allowed us to investigate whether the organization of functional networks between and within individuals was dependent or invariant of timescale (frequency band) [@mostamesadaghiani_OscillationBasedConnectivityArchitecture_2021]. However, filtering epoched data creates edge artifacts at the start and end of each epoch that distort the true signal. Creating longer epochs in the first step provided padding around the edges of each epoch that could be cropped in the third step to remove these edge artifacts; and overlapping epochs in the first step made it possible for the cropped epochs in the third step to be non-overlapping and contiguous with reference to the continuous data, preserving the true signal across the length of the recording. The 5 second duration was selected based on the minimum epoch length required to get reliable phase coupling estimates in the delta band.

## Analyses

### Functional Connectivity

Functional connectivity was estimated between all pairs of EEG channels using the phase lag index [PLI\; @stametal_PhaseLagIndex_2007] and the orthogonalized amplitude envelope correlation [AEC\; @hippetal_LargescaleCorticalCorrelation_2012], which measure phase coupling and amplitude coupling, respectively. Both the phase lag index and the orthogonalized amplitude envelope correlation account for the effects of field spread and volume conduction, reducing the possibility of spurious coupling between channels from influencing our functional connectivity estimates [@bastosschoffelen_TutorialReviewFunctional_2016]. The resulting functional connectivity estimates from each recording were collected into twelve symmetrical $64 \times 64$ matrices called *functional connectomes* per frequency band and measure, which reflected electrophysiological cortical functional networks derived from averaged phase or amplitude coupling between each pair of channels. These functional connectomes were the basic unit of observation for subsequent analyses.

#### Phase coupling

The average amount of phase coupling between pairs of sensors was estimated in each recording using the phase lag index [PLI\; @stametal_PhaseLagIndex_2007]. The phase lag index estimates the asymmetry of the distribution of phase angle differences between two signals $x$ and $y$ [@stametal_PhaseLagIndex_2007; @vincketal_ImprovedIndexPhasesynchronization_2011], given by:

$$
\mathrm{PLI}(x, y) = 
  \frac 1 n \sum_{f = 1}^n
  \left \vert
  \frac 1 N \sum_{i = 1}^N
  \operatorname{sign}( \operatorname{imag}(S_{xyfi}) ) 
  \right \vert,
$$

where $n$ is the number of frequency bins in each frequency band, $N$ is the number of epochs, $\operatorname{sign}(\cdot)$ is the signum operator, $\operatorname{imag}(\cdot)$ is the imaginary operator, and $S_{xyi}$ is the complex-valued cross spectral density between two sensors $x$ and $y$ at the individual frequency bins $f$ in the $i$th epoch, from which we extract the phase angle differences at each frequency bin.

We estimated the cross spectral density between two signals $x$ and $y$ using multitaper spectral estimation [@babadibrown_ReviewMultitaperSpectral_2014; @thomson_SpectrumEstimationHarmonic_1982] with digital prolate spheroidal sequence (DPSS) [@slepianpollak_ProlateSpheroidalWave_1961] windows. Seven tapers were used for each frequency band. The individual frequency bins used for each frequency band was determined by calculating the Discrete Fourier Transform sample frequencies for a 1001 sample window (corresponding to a 5 second epoch) and a sample space of 0.005 (the inverse of the 200 Hz sampling rate). This resulted in 501 frequency bins spaced at roughly 0.2 Hz intervals between zero and 100 Hz. Then for each frequency band we simply selected the frequency bins that were equal to or between the minimum and maximum frequencies of each frequency band. 

The phase lag index takes values between 0 and 1. A value of 0 indicates either no phase coupling or phase coupling with a phase angle difference centred around 0 or 180 degrees, and a value of 1 indicates perfect phase coupling with a consistent nonzero phase angle difference. By only considering consistent nonzero phase angle differences as indicators of phase coupling between two sensors, the phase lag index ignores phase coupling that could be explained by volume conduction from a single common source (at the cost of also ignoring non-spurious zero lag coupling), making it a sound measure of the interactions between different underlying neural sources [@stametal_PhaseLagIndex_2007].

```{r rfftfreq, eval=FALSE}
n_times <- 1000
n_freqs <- n_times + 1
sampling_rate <- 200
sample_spacing <- 1 / sampling_rate
my_sequence <- 0:(n_times / 2)
rfftfrreqs <- my_sequence / (sample_spacing * n_freqs)
```

<!--
Note: This is how MNE python defines the equation

$$
\mathit{PLI} = \vert \operatorname{E} ( \operatorname{sign}( \operatorname{imag}(S_{xy}) ) ) \vert,
$$

Note 2: This is the equivalent equation following Stam using the Hilbert transform:

$$
\mathrm{PLI}(x, y) = \frac 1 N \sum_{i = 1}^N
         \left \vert
           \frac 1 n \sum_{j = 1}^n
             \operatorname{sign} \left (
               \operatorname{Im} \left (e^{i (\phi_x - \phi_y)_{ij}} \right )
             \right )
         \right \vert,
$$

where $\operatorname{sign}(\cdot)$ is the signum operator, $\operatorname{Im}(\cdot)$ is the imaginary operator, and $e^{i(\cdot)}$ is Euler's formula, which we apply to difference of the phase angles between $\phi_x$ and $\phi_y$ at the individual sample points $j$ in the $i$th epoch.
-->

#### Amplitude coupling

<!-- I have manually checked the internals and output of the `mne.connectivity.envelope_correlation()` function and it works exactly as described below. Using Michael Cohen's terminology, it estimates connectivity over time, which is appropriate for resting state data. -->

The average amount of amplitude coupling between pairs of sensors was estimated in each recording using the orthogonalized amplitude envelope correlation [AEC\; @hippetal_LargescaleCorticalCorrelation_2012]. The orthogonalized amplitude envelope correlation estimates the absolute Pearson correlation coefficient of the amplitude envelopes between two orthogonalized complex-valued analytic signals $x$ and $y$ [@hippetal_LargescaleCorticalCorrelation_2012], given by:

$$
\mathrm{AEC}(x, y) =
  \left \vert
    \frac 1 N \sum_{i = 1}^N
    \frac{
      \sum_{t = 1}^n (x_{it} - \bar x_i)(y_{it} - \bar y_i)
    }{
      \sqrt{ \sum_{t = 1}^n (x_{it} - \bar x_i)^2 \sum_{t = 1}^n (y_{it} - \bar y_i)^2 }
    }
 \right \vert,
$$

where $N$ is the number of epochs, $n$ is the number of samples in each epoch, $x_{ij}$ and $y_{ij}$ are the individual sample points $t$ of the amplitude envelopes in the $i$th epoch, and $\bar x_j$ and $\bar y_j$ are the sample means of the amplitude envelopes in the $i$th epoch.

We extracted the analytic signal from each channel's time-course using the Hilbert transform [@stametal_PhaseLagIndex_2007]. Following this, the complex-valued analytic signals $X(a, b)$ and $Y(a, b)$ for each pair of channels were orthogonalized by removing signal components that shared the same phase between the two signals [@hippetal_LargescaleCorticalCorrelation_2012], given by: 

$$
X_{\bot Y}(a, b) = \operatorname{Im} \left(X(a, b) \frac{Y(a, b)^*}{\vert Y(a, b) \vert} \right),
$$

where $Y(a, b)^*$ is the complex conjugate of $X(a, b)$. Similarly to the phase lag index, the orthogonalization procedure used here allowed us to ignore parts of the signal that can be explained by volume conduction from a single common source, making the subsequent amplitude envelope correlations a sound measure of the interactions between different underlying neural sources [@hippetal_LargescaleCorticalCorrelation_2012]. After orthogonalization, the amplitude envelopes of the two analytic signals were computed by taking the absolute value of each signal, then the amplitude envelope correlation between them was estimated. We computed amplitude envelope correlations for both directions of the orthogonalization ($X$ to $Y$, and $Y$ to $X$), then averaged the values to get the final amplitude envelope correlation estimate for each pair.

The amplitude envelope correlation takes values between 0 and 1. A value of 0 indicates no amplitude coupling between the orthogonalized signals, and a value of 1 indicates perfect amplitude coupling with a consistent amplitude envelope correlation between the orthogonalized signals.

#### Interpreting functional connectivity

We use connectivity profile matrices [@demuruetal_FunctionalEffectiveWhole_2017] to compactly display the phase and amplitude coupling functional connectome from each recording. These plots serve as a supplement to our similarity analyses, providing a broad idea of what aspects of functional connectivity are being summarized by a given similarity estimate. Each row shows the vectorized lower-triangle of the phase or amplitude coupling functional connectome from a given recording (i.e., all unique pairs in the connectome), and each column represents a pair of sensors. The strength of coupling between any pair of sensors corresponds to their phase lag index or amplitude envelope correlation estimate and is represented by the colour of that cell in the matrix, with darker colours representing less coupling and brighter colours representing more coupling.

### Functional connectome similarity

The similarity of phase- and amplitude-based functional connectomes was next quantified by estimating the RV coefficient [@robertescoufier_UnifyingToolLinear_1976] between all pairs of functional connectomes from a given individual, session, and state within each frequency band (14,028 pairs total<!--TODO inline code-->). The RV coefficient is a multivariate measure of the linear relationship between two positive semi-definite matrices $\mathbf{X}$ and $\mathbf{Y}$ that takes values between 0 (no linear relationship) and 1 (perfect linear relationship) [@abdiherve_RVCoefficientCongruence_2007; @escoufier_TraitementVariablesVectorielles_1973; @josseholmes_MeasuringMultivariateAssociation_2016; @robertescoufier_UnifyingToolLinear_1976], given by:

$$
\mathrm{RV}(\mathbf{X}, \mathbf{Y}) = \frac{ 
  \operatorname{trace}(\mathbf{ST})
}{
  \sqrt{\operatorname{trace}(\mathbf{SS}) \times \operatorname{trace}(\mathbf{TT})}
},
$$

where $\mathbf{S} = \mathbf{XX}^\mathsf{T}$ and $\mathbf{T} = \mathbf{YY}^\mathsf{T}$. The RV coefficient can be thought of as a generalization of the squared Pearson correlation coefficient between two variables to the case of two sets of variables, where two sets of variables are correlated if the relative position (in Hilbert space) of the observations in one set is similar to the relative position of the observations in the other set [@josseholmes_MeasuringMultivariateAssociation_2016; @mayeretal_ExploratoryAnalysisMultiple_2011]. However, as can be seen in the equation above, unlike the Pearson correlation coefficient, the mean of the observations in a set is not subtracted from its observations when estimating the RV coefficient [@abdiherve_RVCoefficientCongruence_2007]. The RV coefficient is sensitive to both the overall extent and the pattern of coupling, making it a viable measure for studying network variants.

```{r}
which_participant <- "P19"
```

<!-- Figure \@ref(fig:similarity-key) provides a visual depiction of how the similarities between functional connectomes are captured by the RV coefficient. On the left, Figure \@ref(fig:similarity-key)A shows the alpha band phase coupling functional connectomes for participant `r which_participant`; on the right, Figure \@ref(fig:similarity-key)B shows the similarity matrix containing the RV coefficient estimates for all pairs of functional connectomes shown in Figure \@ref(fig:similarity-key)A. -->

```{r similarity-key, eval=FALSE}
#| fig.cap: |
#|   TODO: Write caption.
case_order <- function(participant_ids) {

  tidyr::expand_grid(
    participant = participant_ids,
    session_state = factor(
      c(
        "pre_rc1",
        "pre_rc2",
        "post_rc1",
        "post_rc2",
        "fu_rc1",
        "fu_rc2",
        "pre_ro1",
        "pre_ro2",
        "post_ro1",
        "post_ro2",
        "fu_ro1",
        "fu_ro2"
      )
    )
  ) |>
    dplyr::arrange(participant) |>
    dplyr::mutate(label = paste0(participant, "_", session_state)) |>
    purrr::pluck("label")

}

tar_load(phase_similarity_key_plot_P19_alpha)

phase_connectivity_plots_P19_alpha <- tibble::tibble(
  branches = names(tar_read(phase_connectivity_plot_alpha)),
  plots = tar_read(phase_connectivity_plot_alpha)
) |>
  tidyr::hoist(
    plots,
    participant = list("metadata", "participant"),
    case = list("metadata", "case")
  ) |>
  dplyr::filter(participant == which_participant) |>
  dplyr::arrange(factor(case, levels = case_order(which_participant))) |>
  dplyr::select(plots) |>
  as.list() |>
  purrr::pluck(1) |>
  purrr::map(purrr::pluck, 1)

connectivity_patch <- patchwork::wrap_plots(
    phase_connectivity_plots_P19_alpha,
    ncol = 3, widths = 1,
    guides = "auto"
  ) &
  ggplot2::theme(
    axis.text = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    axis.title = ggplot2::element_blank(),
    plot.margin = grid::unit(c(0.05, 0.05, 0.1, 0.05), "cm"),
    legend.position = "right"
  )

# The facet from the similarity matrix pushes the titles in the top row of
# the connectivity matrix patchwork up, so we have to manually readjust them
# to get the alignment we want. Doing this also duplicates the legends so we
# need to remove those too.
connectivity_patch[[1]] <- connectivity_patch[[1]] +
  ggplot2::theme(
    plot.title = ggplot2::element_text(
      margin = ggplot2::margin(b = -18, unit = "pt")
    ),
    legend.position = "none"
  )
connectivity_patch[[2]] <- connectivity_patch[[2]] +
  ggplot2::theme(
    plot.title = ggplot2::element_text(
      margin = ggplot2::margin(b = -18, unit = "pt")
    ),
    legend.position = "none"
  )
connectivity_patch[[3]] <- connectivity_patch[[3]] +
  ggplot2::theme(
    plot.title = ggplot2::element_text(
      margin = ggplot2::margin(b = -18, unit = "pt")
    ),
    legend.position = "none"
  )

connectivity_patch -
  patchwork::plot_spacer() +
  phase_similarity_key_plot_P19_alpha +
  ggplot2::theme(legend.position = "right") +
  patchwork::plot_layout(widths = c(1, 0.1, 1), guides = "collect") +
  patchwork::plot_annotation(
    tag_levels = list(c("A", rep("", 11), "B"))
  )
```

<!-- After estimating the RV coefficient between all pairs of phase and amplitude coupling functional connectomes within each frequency band, we assessed how functional connectome similarity varied between and within individuals, sessions, and states using data visualization and statistical modelling. -->

<!-- #### Visualizing functional connectome similarity -->

<!-- We collected the RV coefficient estimates into a similarity matrix, and then visualized them with a heat map to examine the amount and pattern of similarity within states, individuals, sessions, and the entire sample. With large effects, we would expect visually obvious patterns of similarity estimates corresponding to the archetypal outcomes depicted in Figure \@ref(fig:similarity-archetype-plots) in the introduction. -->

#### Interpreting functional connectome similarities

We use similarity matrices to examine the similarities of functional connectomes between and within individuals, sessions, and states. When interpreting a similarity matrix, the two most important features are the *strength* and *pattern* of similarities. The strength of similarity between any pair of functional connectomes corresponds to their RV coefficient estimate and is represented by the colour of that cell in the matrix, with darker colours representing less similarity and brighter colours representing more similarity. To interpret the pattern of similarities we first need to consider the ordering of functional connectomes in the matrix. The boxes on the diagonal show within-participant similarities between all twelve functional connectomes from a given participant, the boxes on the off-diagonal show between-participant functional connectome similarities. With this organization in mind, we can examine the similarity matrix for visually obvious patterns of low and high similarity, such as those depicted in Figure \@ref(fig:similarity-archetype-plots) in the introduction.

### Group-level functional connectome similarity contrasts

<!-- Constant dispersion (phi) was used for the model; this doesn't need to be mentioned explicitly, but it's worth leaving a reminder here as a comment. -->

We used a mixed beta regression to model how functional connectome similarity varied between and within individuals, sessions, and states at the group-level for each frequency band [for an accessible overview of mixed beta regression, see @doumaweedon_AnalysingContinuousProportions_2019; @heiss_GuideModelingProportions_2021]. The unit of observation was the pair of functional connectomes used for a given similarity estimate. The response variable was the RV coefficient estimated for each pair, which was modelled with a beta distribution and related to the predictors with the logit link function following the parameterization of @cribari-netozeileis_BetaRegression_2010 and @ferraricribari-neto_BetaRegressionModelling_2004. The predictors were binary indicators (where $0 = \textrm{No}$ and  $1 = \textrm{Yes}$) for whether a pair was within participant, within session, or within state, and their interactions. Because the RV coefficient estimates are based on the similarity of pairs of functional connectomes, we included a random intercept for both the $\mathbf{X}$ and $\mathbf{Y}$ connectome that each observation came from to account for statistical dependencies between observations that had a connectome in common. All random effects were assumed to be normally distributed [@brooksetal_GlmmTMBBalancesSpeed_2017].

We also originally planned to include a random intercept for the participant pair to account for the repeated observation of the same participant pairs, however including this term led to convergence problems for several of our models where the estimate for the variance of this parameter was zero. Although in principle participant pair should have been included in the statistical model as a random intercept to account for the repeated measures design, we decided not to include this parameter for pragmatic reasons so all our models would converge. The effect of not including participant pair was negligible for point estimates, which were similar or equivalent between models where it was and was not included; but was noticeable for interval estimates, which were generally wider by a factor of two to four when it was included compared to when it was not included. This difference did not meaningfully change the conclusions drawn from our results, however.

The fit of the model was assessed using the following diagnostics: Posterior predictive checks---wherein we simulated replicated data under the fitted model and compared these to the observed data---were used to check for systematic differences between the fitted model and observed data [@gelmanetal_BayesianDataAnalysis_2013; @gelmanetal_RegressionOtherStories_2020; @gelmanhill_DataAnalysisUsing_2006]. Randomized quantile residuals plotted against uniform distribution quantiles were used to check for signs of model misspecification [@dunnsmyth_RandomizedQuantileResiduals_1996; @hartiglohse_DHARMaResidualDiagnostics_2022]. Quantiles of the random effects plotted against standard normal distribution quantiles were used to check if the random effects were normally distributed; however, generalized linear mixed effects models have a large degree of robustness against misspecifying the shape of the random effects distribution [see @mccullochneuhaus_MisspecifyingShapeRandom_2011]. Variance Inflation Factors were used to check for multicollinearity between the predictors [@foxmonette_GeneralizedCollinearityDiagnostics_1992; @marcoulidesraykov_EvaluationVarianceInflation_2019; @obrien_CautionRegardingRules_2007], where a value of less than five as indicated low multicollinearity between the predictors, values between five and ten moderate, and values greater than ten high and not tolerable [@jamesetal_IntroductionStatisticalLearning_2021].

After fitting the model we constructed a reference grid using estimated marginal means [@lenthetal_EmmeansEstimatedMarginal_2022; @searleetal_PopulationMarginalMeans_1980], which were back-transformed to the response scale (0-1) for interpretability. The estimated marginal means were then used to estimate the difference in functional connectome similarity within and between participants using pairwise contrasts. Differences were estimated for (1) the overall difference in similarity within and between participants, which we term the *main effect*; (2) the difference in similarity within and between participants for each level of one predictor (e.g., within session similarity) while averaging over levels of the other predictor (e.g., within and between state similarity); (3) the difference in similarity within and between participants for the unique combinations within and between session and state. For any of these contrasts: A difference of zero indicated equal amounts of functional connectome similarity within and between participants, a positive difference indicated more similarity within than between participants, and a negative difference indicated more similarity between than within participants. <!-- These contrasts were the estimands of our model and will be the focus of discussion in the results section. -->

#### Interpreting group-level contrasts

We use interval plots to report the group-level contrasts estimating the difference in functional connectome similarity within and between participants at various levels of the session and state predictors. To interpret these contrasts, we report compatibility intervals (CIs), which are equivalent to classical confidence intervals [@amrheingreenland_DiscussPracticalImportance_2022]. An $x\%$ compatibility interval shows the effect sizes most compatible with our data, given the correctness of the set of statistical assumptions used to compute the interval, which we call the *background model* [see @amrheingreenland_DiscussPracticalImportance_2022]. As discussed by @amrheinetal_ScientistsRiseStatistical_2019, there are two important points to keep in mind when interpreting compatibility intervals. First, although interval shows the values most compatible with our data, it does not mean values outside the interval are incompatible; they are merely less compatible. Second, the point estimate and values near it are more compatible with our data than values near the limits of the interval; we use both 95% and 66% compatibility intervals in our plots to highlight this. Additionally, given that the correctness of all assumptions used to compute our estimates was questionable (e.g., we knowingly misspecified the random effects of the mixed beta regressions), we emphasize that our estimates likely understate uncertainty about the effect sizes most compatible with our data, and should not be taken as showing some general truth. Based on the results of @grattonetal_FunctionalBrainNetworks_2018, we might consider contrasts showing that functional connectomes were approximately 0.2 points (on the response scale) more similar within participants than between participants to correspond to what has been found with shorter fMRI scanning times (depending on the task, anywhere from 5 to 15 minutes), and approximately 0.3 points more similar to correspond to what has been found with longer scanning times (depending on the task, anywhere from 25 to 75 minutes),[^2] keeping in mind that finding equivalent effect sizes would be surprising, given the differences in measurement, design, and analysis between our studies. As a lower bound, we considered differences of approximately 0.1 points to be a small but meaningful effect size, as differences of this size might still provide weak evidence for the presence of network variants<!-- given the limitations of our study (see discussion) -->.

### Individual-level functional connectome similarity contrasts

To explore how well the group-level model and contrasts represented individual differences in our sample, we also fit a mixed beta regression for each participant, following the same parameterizations as the group-level model. These individual-level models were followed-up using the same pairwise contrasts as in the group-level model, and comparisons between the group-level and individual-level contrasts were done visually.

#### Interpreting individual-level contrasts

We use ridge plots to report the individual-level contrasts estimating the difference in functional connectome similarity within and between participants at various levels of the session and state predictors. To interpret these contrasts, we report 95% compatibility distributions, which are equivalent to classical confidence distributions [@schwederhjort_ConfidenceLikelihoodProbability_2016; @xiesingh_ConfidenceDistributionFrequentist_2013]. Like with a compatibility interval, a 95% compatibility distribution shows the effect sizes most compatible with our data, given the background model, and is a sample-dependent distribution representing compatibility intervals of all levels for a parameter [@xiesingh_ConfidenceDistributionFrequentist_2013]. We used scaled and shifted $t$ distributions as the sampling distribution for the individual-level contrasts, using the point estimate, standard error, and degrees of freedom as parameters for the distribution. The peak of the distribution corresponds to the point estimate, and changes in the density of the distribution correspond to differences in compatibility values have with our data.

<!-- ## Data and code availability -->

<!-- The authors do not have the license to make the data publicly available. Please contact the corresponding author (name@email.com) to discuss data access requests. -->

<!-- The raw and preprocessed EEG recordings used in this study are not currently openly available. All other data and code used in this study is openly available, and can be accessed at the study's GitHub repository <https://github.com/mccarthy-m-g/mccarthy-20XX> or Open Science Framework (OSF) repository <https://osf.io/xztdk/> (DOI: <https://doi.org/10.5281/zenodo.6578410>). Specifically: All functional connectivity data is licensed under the Creative Commons CC0 1.0 Universal, and all code is licensed under the MIT License. A copy of these licences and their terms can be found in the study's GitHub or OSF repository. -->

<!-- Footnotes start --------------------------------------------------------->

[^2]: These values were obtained by back-transforming the Fisher-transformed Pearson correlation coefficients for the group and individual effects reported in Supplemental Figures 2D and 2E in @grattonetal_FunctionalBrainNetworks_2018, then taking their difference.

<!-- [^99]: Author's note: We have not yet created the reproducible environment. -->

<!-- Footnotes end ----------------------------------------------------------->
